{"timestamp": 1680715157.244643, "stored_source_code": "# declare a list tasks whose products you want to use as inputs\nupstream = ['get']\nproduct = {\n    \"nb\": \"outputs/output.ipynb\",\n    \"data\": \"outputs/clean_data.csv\"\n}\nimport numpy as np #linear algebra\nimport pandas as pd #data manipulation and analysis\nimport seaborn as sns #data visualization\nimport matplotlib.pyplot as plt #data visualization\nimport sklearn.preprocessing as skp #machine learning (preprocessing)\nimport sklearn.cluster as skc #machine learning (clustering)\nimport warnings # ignore warnings\nwarnings.filterwarnings('ignore')\n\n\nimport numpy as np #linear algebra\nimport pandas as pd #data manipulation and analysis\nfrom sklearn import preprocessing\n## INTRO TO DATA\ndf = pd.read_csv(upstream['get']['data'])\ndf.info()\ndf.describe()\n### Drop unnecessary Columns\n# Specify the cols to drop\nto_drop = [\n    'parts_only', 'dps_classification', \"dispatch_number\"\n]\n\n# Drop them\ndf.drop(to_drop, axis='columns', inplace=True)\n### Distribution of Columns\n# # Visualize the distribution of each variable.\n# plt.figure(figsize=(12,16))\n# for i, j in enumerate(df.describe().columns):\n#     plt.subplot(5,2, i+1)\n#     sns.distplot(x=df[j])\n#     plt.xlabel(j)\n#     plt.title('{} Distribution'.format(j))\n#     plt.subplots_adjust(wspace=.2, hspace=.5)\n#     plt.tight_layout()\n# plt.show()\n## OUTLIERS FOR SYSTEM_AGE\n\ndf.loc[df['system_age'] > 10000\n\n       ]\ndf.system_age[df['system_age'] > 10000] = None\n### Filling missing data with mean\ndf.system_age[df['system_age'] < 0] = None\ndf.system_age.fillna(df.system_age.mean(), inplace=True)\ndf.loc[df['system_age'].isnull()\n       ]\n## DROPPING DUPLICATE ROWS\ndf.duplicated().sum()\ndf.loc[df.\n       duplicated(), :]\ndf = df.drop_duplicates(keep=False)\ndf.info()\n## CONVERTING TO DATETIME + CREATING NEW COLUMN\ndft = df.copy()\ndft[\"close_dts\"] = pd.to_datetime(df.close_dts, format=\"%H:%M:%S\", errors='raise')\ndft[\"close_dts\"] =dft[\"close_dts\"].dt.time\ndft.head(10)\ndft[\"created_dts\"] = pd.to_datetime(df.created_dts, format = \"%H:%M:%S\" , errors='raise')\ndft[\"created_dts\"] =dft[\"created_dts\"].dt.time\ndft.head(10\n        )\n\ndf[\"created_date\"] = pd.to_datetime(df.created_date, format = \"%m/%d/%Y %H:%M\" , errors='raise')\n## DEALING WITH MISSING DATA\ndf.head(10)\n\ndf[\"created_dts\"] = pd.to_datetime(df.created_dts, format = \"%H:%M:%S\" , errors='raise')\ndf[\"close_dts\"] = pd.to_datetime(df.close_dts, format=\"%H:%M:%S\", errors='raise')\ndf['journey_time'] = df['close_dts'] - df[\"created_dts\"]\ndf.journey_time[df['journey_time'].dt.days != 0] = None\ndf.head(10)\n\ndf[\"seconds\"] = df.journey_time.dt.total_seconds()\ndf.head(10)\ndf.info()\nmissing_data = pd.DataFrame({'total_missing': df.isnull().sum(), 'perc_missing': (df.isnull().sum()/18146)*100})\nmissing_data\ndf.info()\n### Filling missing values for countries with \"No Country\"\ndf.country_name_dawn.fillna(\"No Country\", inplace=True)\ndf.total_activity_count.fillna(df.total_activity_count.mean(), inplace=True)\ndf.total_inbounf_count.fillna(df.total_inbounf_count.mean(), inplace=True)\ndf.journey_time.fillna(df.journey_time.mean(), inplace=True)\ndf.close_dts.fillna(df.close_dts.mean(), inplace=True)\ndf.seconds.fillna(df.seconds.mean(), inplace= True)\ndf.country_name_dawn.isnull().sum()\n## GRAPHS + CONVERTING 6 COLUMNS TO CATEGORY DTYPE\n### Checking possible columns to convert to category dtype\n### Convert to category (commented due to adding more graphs)\n#df.commodity_desc = df.commodity_desc.astype('category')\n#df.prod_desc = df.prod_desc.astype('category')\n#df.contact_method_name = df.contact_method_name.astype('category')\n#df.contact_method = df.contact_method.astype('category')\n#df.new_warranty_type = df.new_warranty_type.astype('category')\n#df.warranty_status = df.warranty_status.astype('category')\ndf.info()\n### Comparing similar columns\n### Adding Continent Column\nasia = ['Afghanistan', 'Bahrain', 'United Arab Emirates','Saudi Arabia', 'Kuwait', 'Qatar', 'Oman',\n       'Sultanate of Oman','Lebanon', 'Iraq', 'Yemen', 'Pakistan', 'Lebanon', 'Philippines', 'Jordan', 'Taiwan',\n       'Indonesia', 'Singapore', 'China', 'Korea', 'Hong Kong', 'Malaysia', 'India', 'APJ Support', 'Japan', 'Thailand']\neurope = ['Germany','Spain', 'France', 'Italy', 'Netherlands', 'Norway', 'Sweden','Czech Republic', 'Finland',\n          'Denmark', 'Switzerland', 'United Kingdom', 'Ireland', 'Poland', 'Greece','Austria',\n          'Bulgaria', 'Hungary', 'Luxembourg', 'Romania' , 'Slovakia', 'Estonia', 'Slovenia','Portugal',\n          'Croatia', 'Lithuania', 'Latvia','Serbia', 'Estonia', 'Iceland', 'Western Europe' , 'CEE eCis' , 'Belgium']\nsa =['Chile', 'Peru', 'Argentina', 'Colombia', 'Mexico', 'Brazil']\nna = ['United States', 'Canada']\nafrica = ['South Africa']\noceania = ['Australia', 'New Zealand']\n\n\ndef GetConti(country):\n    if country in asia:\n        return \"Asia\"\n    elif country in europe:\n        return \"Europe\"\n    elif country in africa:\n        return \"Africa\"\n    elif country in na:\n        return \"North America\"\n    elif country in sa:\n        return \"South America\"\n    elif country in oceania:\n        return \"Oceania\"\n    else:\n        return \"No country\"\n\n\ndf['Continent'] = df['country_name_dawn'].apply(lambda x: GetConti(x))\ndf.head(10)\n### Encoding Continents\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nle = preprocessing.LabelEncoder()\ndf['continent_cat'] = le.fit_transform(df['Continent'])\ndf['country_cat'] = le.fit_transform(df['country_name_dawn'])\ndf.info()\ndf['date_delta'] = (df['created_date'] - df['created_date'].min())  / np.timedelta64(1,'D')\ndf.head(10)\n\n\nto_drop2 = [\n    \"last_updated_dts\", \"close_dts\",\n    \"created_dts\", \"created_date\", \"tag_id\",  \"contact_method\", \"contact_method_name\",\n    \"journey_time\", \"seconds\"\n]\n\n# Drop them\ndf.drop(to_drop2, axis='columns', inplace=True)\ndf.to_csv(str(product['data']), index=False)\n", "params": {}}